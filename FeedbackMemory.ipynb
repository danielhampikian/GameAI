{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including OpenAI and Claude API clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import openai\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "claude_api_key = os.getenv('CLAUDE_API_KEY')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize LLMs\n",
    "Initialize the Google, OpenAI and Claude language models using their respective API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLMs\n",
    "\n",
    "# Test OpenAI API call\n",
    "def call_openai_api(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci-codex\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Test Claude API call\n",
    "def test_claude_api():\n",
    "    prompt = \"Hello, Claude!\"\n",
    "    response = call_claude_api(prompt)\n",
    "    return response['choices'][0]['text'].strip()\n",
    "\n",
    "# Test teh Gemini API call:\n",
    "def test_gemini_api():\n",
    "    prompt = \"Hello, Gemini!\"\n",
    "    response = call_gemini_api(prompt)\n",
    "    return response['choices'][0]['text'].strip()\n",
    "\n",
    "# Test the API calls\n",
    "openai_response = call_openai_api(\"Hello, OpenAI!\")\n",
    "claude_response = test_claude_api()\n",
    "gemini_response = test_gemini_api()\n",
    "\n",
    "openai_response, claude_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini, ChatGPT, and Sonnet\n",
    "\n",
    "# Test Gemini API call\n",
    "def call_gemini_api(prompt):\n",
    "    response = requests.post(\n",
    "        'https://api.gemini.ai/v1/completions',\n",
    "        headers={'Authorization': f'Bearer {gemini_api_key}'},\n",
    "        json={'prompt': prompt, 'max_tokens': 150}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "# Test ChatGPT API call\n",
    "def call_chatgpt_api(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Test Sonnet API call\n",
    "def call_sonnet_api(prompt):\n",
    "    response = requests.post(\n",
    "        'https://api.sonnet.ai/v1/completions',\n",
    "        headers={'Authorization': f'Bearer {sonnet_api_key}'},\n",
    "        json={'prompt': prompt, 'max_tokens': 150}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "# Test the API calls\n",
    "gemini_response = call_gemini_api(\"Hello, Gemini!\")\n",
    "chatgpt_response = call_chatgpt_api(\"Hello, ChatGPT!\")\n",
    "sonnet_response = call_sonnet_api(\"Hello, Sonnet!\")\n",
    "\n",
    "print(gemini_response, chatgpt_response, sonnet_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Interaction Variable\n",
    "Define a variable to limit the number of interactions between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Interaction Variable\n",
    "interaction_limit = 10  # Set the number of interactions between the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Language Game\n",
    "Define a function where one model creates a language game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Language Game\n",
    "def create_language_game(prompt):\n",
    "    # OpenAI creates the initial language game\n",
    "    openai_game = call_openai_api(prompt)\n",
    "    \n",
    "    # Claude evaluates the game\n",
    "    claude_feedback = call_claude_api(f\"Evaluate this game: {openai_game}\")\n",
    "    \n",
    "    return openai_game, claude_feedback\n",
    "\n",
    "# Example usage\n",
    "initial_prompt = \"Create a fun word association game.\"\n",
    "game, feedback = create_language_game(initial_prompt)\n",
    "\n",
    "game, feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Game\n",
    "Define a function where the other model evaluates the game as fun or not and provides feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Game\n",
    "def evaluate_game(game, feedback_prompt):\n",
    "    # Claude evaluates the game\n",
    "    claude_feedback = call_claude_api(feedback_prompt.format(game=game))\n",
    "    \n",
    "    # OpenAI provides feedback on Claude's evaluation\n",
    "    openai_feedback = call_openai_api(f\"Evaluate this feedback: {claude_feedback['choices'][0]['text'].strip()}\")\n",
    "    \n",
    "    return claude_feedback['choices'][0]['text'].strip(), openai_feedback\n",
    "\n",
    "# Example usage\n",
    "game = \"A word association game where players take turns saying words that are related to the previous word.\"\n",
    "feedback_prompt = \"Evaluate this game: {game}\"\n",
    "claude_feedback, openai_feedback = evaluate_game(game, feedback_prompt)\n",
    "\n",
    "claude_feedback, openai_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate Game Creation and Evaluation\n",
    "Implement a loop to alternate between game creation and evaluation based on the interaction variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate Game Creation and Evaluation\n",
    "def iterate_game_creation_and_evaluation(initial_prompt, interaction_limit):\n",
    "    current_prompt = initial_prompt\n",
    "    for i in range(interaction_limit):\n",
    "        # OpenAI creates the game\n",
    "        openai_game = call_openai_api(current_prompt)\n",
    "        \n",
    "        # Claude evaluates the game\n",
    "        claude_feedback = call_claude_api(f\"Evaluate this game: {openai_game}\")\n",
    "        \n",
    "        # OpenAI provides feedback on Claude's evaluation\n",
    "        openai_feedback = call_openai_api(f\"Evaluate this feedback: {claude_feedback['choices'][0]['text'].strip()}\")\n",
    "        \n",
    "        # Update the prompt for the next iteration\n",
    "        current_prompt = f\"Improve this game based on feedback: {openai_feedback}\"\n",
    "        \n",
    "        # Print the results of the current iteration\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Game: {openai_game}\")\n",
    "        print(f\"Claude's Feedback: {claude_feedback['choices'][0]['text'].strip()}\")\n",
    "        print(f\"OpenAI's Feedback: {openai_feedback}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Example usage\n",
    "initial_prompt = \"Create a fun word association game.\"\n",
    "iterate_game_creation_and_evaluation(initial_prompt, interaction_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "# Initialize LLMs\n",
    "openai.api_key = 'your_openai_api_key'\n",
    "claude_api_key = 'your_claude_api_key'\n",
    "gemini_api_key = 'your_gemini_api_key'\n",
    "\n",
    "# Define Interaction Variable\n",
    "interaction_limit = 10\n",
    "\n",
    "# User-defined Variables\n",
    "thing_to_create = \"language game\"  # Change this to \"machine learning algorithm\", \"marketing campaign strategy\", etc.\n",
    "evaluation_criteria = \"fun\"  # Change this to \"usefulness\", \"effectiveness\", \"uniqueness\", etc.\n",
    "\n",
    "# Initialize Feedback Variables\n",
    "feedback_buffer = []\n",
    "collective_feedback = []\n",
    "\n",
    "# Function to Create Thing\n",
    "def create_thing(model, feedback):\n",
    "    prompt = f\"Create a {thing_to_create} based on the following feedback: {feedback}\"\n",
    "    if model == 'openai':\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=150)\n",
    "        return response.choices[0].text.strip()\n",
    "    elif model == 'claude':\n",
    "        response = requests.post('https://api.claude.ai/v1/completions', headers={'Authorization': f'Bearer {claude_api_key}'}, json={'prompt': prompt, 'max_tokens': 150})\n",
    "        return response.json()['choices'][0]['text'].strip()\n",
    "\n",
    "# Function to Evaluate Thing\n",
    "def evaluate_thing(model, thing):\n",
    "    prompt = f\"Evaluate the following {thing_to_create} for {evaluation_criteria}: {thing}\"\n",
    "    if model == 'openai':\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=50)\n",
    "        return response.choices[0].text.strip()\n",
    "    elif model == 'claude':\n",
    "        response = requests.post('https://api.claude.ai/v1/completions', headers={'Authorization': f'Bearer {claude_api_key}'}, json={'prompt': prompt, 'max_tokens': 50})\n",
    "        return response.json()['choices'][0]['text'].strip()\n",
    "\n",
    "# Function to Evaluate Feedback using Google Gemini\n",
    "def evaluate_feedback(feedback):\n",
    "    prompt = f\"Evaluate the usefulness of the following feedback for creating a good {thing_to_create}: {feedback}\"\n",
    "    response = requests.post('https://api.gemini.ai/v1/completions', headers={'Authorization': f'Bearer {gemini_api_key}'}, json={'prompt': prompt, 'max_tokens': 50})\n",
    "    return response.json()['choices'][0]['text'].strip()\n",
    "\n",
    "# Main Interaction Loop\n",
    "for i in range(interaction_limit):\n",
    "    # Create Thing\n",
    "    if i % 2 == 0:\n",
    "        thing = create_thing('openai', collective_feedback)\n",
    "    else:\n",
    "        thing = create_thing('claude', collective_feedback)\n",
    "    \n",
    "    # Evaluate Thing\n",
    "    if i % 2 == 0:\n",
    "        feedback = evaluate_thing('claude', thing)\n",
    "    else:\n",
    "        feedback = evaluate_thing('openai', thing)\n",
    "    \n",
    "    # Add Feedback to Buffer\n",
    "    feedback_buffer.append(feedback)\n",
    "    \n",
    "    # Evaluate Feedback Buffer\n",
    "    useful_feedback = []\n",
    "    for fb in feedback_buffer:\n",
    "        evaluation = evaluate_feedback(fb)\n",
    "        if \"useful\" in evaluation:\n",
    "            useful_feedback.append(fb)\n",
    "    \n",
    "    # Update Collective Feedback\n",
    "    collective_feedback = useful_feedback\n",
    "\n",
    "    # Print Current Thing and Feedback\n",
    "    print(f\"Round {i+1}\")\n",
    "    print(f\"{thing_to_create.capitalize()}: {thing}\")\n",
    "    print(f\"Feedback: {feedback}\")\n",
    "    print(f\"Collective Feedback: {collective_feedback}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import openai\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "claude_api_key = os.getenv('CLAUDE_API_KEY')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "# Define Interaction Variable\n",
    "interaction_limit = 10\n",
    "\n",
    "# User-defined Variables\n",
    "thing_to_create = \"language game\"  # Change this to \"machine learning algorithm\", \"marketing campaign strategy\", etc.\n",
    "evaluation_criteria = \"fun\"  # Change this to \"usefulness\", \"effectiveness\", \"uniqueness\", etc.\n",
    "\n",
    "# Initialize Feedback Variables\n",
    "feedback_buffer = []\n",
    "collective_feedback = []\n",
    "\n",
    "# Function to Create Thing\n",
    "def create_thing(model, feedback):\n",
    "    prompt = f\"Create a {thing_to_create} based on the following feedback: {feedback}\"\n",
    "    if model == 'openai':\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=150)\n",
    "        return response.choices[0].text.strip()\n",
    "    elif model == 'claude':\n",
    "        response = requests.post('https://api.claude.ai/v1/completions', headers={'Authorization': f'Bearer {claude_api_key}'}, json={'prompt': prompt, 'max_tokens': 150})\n",
    "        return response.json()['choices'][0]['text'].strip()\n",
    "\n",
    "# Function to Evaluate Thing\n",
    "def evaluate_thing(model, thing):\n",
    "    prompt = f\"Evaluate the following {thing_to_create} for {evaluation_criteria}: {thing}\"\n",
    "    if model == 'openai':\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=50)\n",
    "        return response.choices[0].text.strip()\n",
    "    elif model == 'claude':\n",
    "        response = requests.post('https://api.claude.ai/v1/completions', headers={'Authorization': f'Bearer {claude_api_key}'}, json={'prompt': prompt, 'max_tokens': 50})\n",
    "        return response.json()['choices'][0]['text'].strip()\n",
    "\n",
    "# Function to Evaluate Feedback using Google Gemini\n",
    "def evaluate_feedback(feedback):\n",
    "    prompt = f\"Evaluate the usefulness of the following feedback for creating a good {thing_to_create}: {feedback}\"\n",
    "    response = requests.post('https://api.gemini.ai/v1/completions', headers={'Authorization': f'Bearer {gemini_api_key}'}, json={'prompt': prompt, 'max_tokens': 50})\n",
    "    return response.json()['choices'][0]['text'].strip()\n",
    "\n",
    "# Main Interaction Loop\n",
    "for i in range(interaction_limit):\n",
    "    # Create Thing\n",
    "    if i % 2 == 0:\n",
    "        thing = create_thing('openai', collective_feedback)\n",
    "    else:\n",
    "        thing = create_thing('claude', collective_feedback)\n",
    "    \n",
    "    # Evaluate Thing\n",
    "    if i % 2 == 0:\n",
    "        feedback = evaluate_thing('claude', thing)\n",
    "    else:\n",
    "        feedback = evaluate_thing('openai', thing)\n",
    "    \n",
    "    # Add Feedback to Buffer\n",
    "    feedback_buffer.append(feedback)\n",
    "    \n",
    "    # Evaluate Feedback Buffer\n",
    "    useful_feedback = []\n",
    "    for fb in feedback_buffer:\n",
    "        evaluation = evaluate_feedback(fb)\n",
    "        if \"useful\" in evaluation:\n",
    "            useful_feedback.append(fb)\n",
    "    \n",
    "    # Update Collective Feedback\n",
    "    collective_feedback = useful_feedback\n",
    "\n",
    "    # Print Current Thing and Feedback\n",
    "    print(f\"Round {i+1}\")\n",
    "    print(f\"{thing_to_create.capitalize()}: {thing}\")\n",
    "    print(f\"Feedback: {feedback}\")\n",
    "    print(f\"Collective Feedback: {collective_feedback}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
